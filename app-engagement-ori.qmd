# Attempts to Document Metrics and Data Issues

On September 26, members of the statistics department contacted several members of the Office of Research and Innovation and the team reported to be responsible for assembling the data and the analysis of the data used as quantitative measures of department performance during the budget reduction process.

---

> Everyone,
> 
> The Statistics department has been preparing for the APC hearing by digging into the data, and we have discovered a problem with implications not only for the budget proposal but also for UNL's plans to rejoin the AAU.  IANR leadership has indicated that any issues with the metrics used for budget cuts should be brought to the attention of ORI (for research) as soon as possible. 
> 
> We have discovered that the UNL computations based on SRI produce misleading results (e.g. the z-score comparison method). Yesterday, we met with an Academic Analytics analyst and confirmed our suspicions. Ultimately, because SRI is a discipline-specific weighted average of different research factors, creating z-scores from SRI metrics is problematic and destroys the signal available in the data, particularly when those scores are calculated across different disciplines with different weightings. There are alternatives that would allow for cross-department comparisons, and we would be happy to discuss those alternatives. 
> 
> In the case of the Statistics department, the SRI numbers from Academic Analytics indicate that we are performing at a level of productivity equivalent to leading departments in Statistics — Iowa State, Michigan State, and Univ Illinois Urbana-Champaign, among others. Obviously, this is a far cry from the z-score SRI provided to the department that indicates that we're performing poorly relative to other departments on campus. 
> 
> We would like to meet briefly at some point between now and Tuesday to explain the issue and demonstrate the problem for our department, because this discovery has the potential to inflame an already volatile situation as campus reacts to the proposed cuts. If we have missed anyone who needs to be included in this discussion, please feel free to forward this and to include them in the meeting. 
> 
> Thanks,

---

We received a response back from someone in ORI (names excluded because they really aren't necessary here). 


> Apologies for the delay in getting back to you sooner, I was in meetings all day yesterday and had a university event that ran late into the evening.
> 
> The SRI for Statistics when the data snapshot was taken in May using AAU public institutions as a peer group was -.1. The Z score that resulted when comparing Statistics SRI to other UNL departments was +.549 indicating that on the SRI metric, Statistics is performing positively relative to other departments on campus.
> 
> Please let me know if you’re seeing something else in the data which leads to your understanding that the department was performing poorly relative to other departments on campus.
> 
> Kind regards,

---

Well, that's great, but that wasn't the issue we raised at all. 
We specifically identified that SRI **z-score calculations** were problematic, and that we'd confirmed with Academic Analytics that cross-discipline calculations are not appropriate using SRI (0.4) or custom SRI (-0.1). 
As we only had data from statistics, that was the only data we could use to demonstrate the problem -- but the issue really wasn't that Statistics had low scores so much as that the method was incorrect for the data. 

---

> <name>, that's not the issue we want to discuss. The issue is the way that UNL has used SRI - a z-score is fundamentally inappropriate for this comparison. This has several implications beyond statistics that I want to make you aware of — there are at least 11 departments that are absolutely hurt by the way the averaging process was performed. I recognize that SRI isn't the only metric used (but that is itself a concern — there are some other issues with how the research metrics are put together). 

> For what it's worth, we confirmed our interpretation of this issue with someone at Academic Analytics before we reached out. So while yes, this has some implications for our department, it has many more implications in terms of how the decisions were made to cut departments overall. If you're willing to meet at some point today I would be happy to stop by. 

---

Another faculty member responded in kind: 

> The treatment of SRI is only one of the issues that we found in the analysis. I’d be happy to show what you are missing when dealing with SRI simply as one of the metrics. 
Grant numbers are severely underreported for Statistics faculty but included in the metrics multiple times.
Despite being assured that faculty with secondary appointments would be appropriately included in the evaluation, this has not happened for any of the joint appointees in Statistics.
I am also worried about the fallout from excluding the performance of 1/4th of the faculty hired after the cutoff date for Academic Analytics. 

> I realize that we will not change policies at this stage, but I would like to give you a chance to handle the factual errors before this becomes public knowledge and further damages the university’s reputation beyond the initial proposal to cut Statistics. 

---

